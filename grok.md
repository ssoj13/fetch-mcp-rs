# Анализ приложения fetch-mcp-rs

## Общий обзор
Приложение является Rust-сервером для MCP (Model Context Protocol), предоставляющим 13+ инструментов для извлечения веб-контента. Проект компилируется без ошибок и предупреждений от clippy.

## Структура проекта
- **Язык**: Rust 2021 edition
- **Основные зависимости**: reqwest, tokio, rmcp, scraper, readability и др.
- **Модули**: 17 модулей в src/, включая fetch, metadata, search, pdf, image и т.д.
- **Тесты**: Минимальное покрытие тестами (только в robots.rs)

## Найденные проблемы и рекомендации

### 1. Логические ошибки и потенциальные баги
- **В main.rs (инструмент fetch)**: Параметры `start_index` и `max_length` не валидируются. Если `start_index` >= длина контента, слайсинг может вернуть пустую строку или некорректные данные. Рекомендуется добавить валидацию: `start_index` должен быть < длины контента.
- **HTTP stream mode**: В main.rs есть аргумент `--port` для HTTP stream mode, но реализация отсутствует (TODO). Либо реализовать, либо убрать аргумент.

### 2. Мертвый код и неиспользуемые элементы
- **fetch.rs**: Функция `detect_content_type` и enum `ContentType` помечены `#[allow(dead_code)]`, но не используются нигде в коде. Можно удалить.
- **Неиспользуемые зависимости** (потенциально):
  - `webpage`: Перечислена в Cargo.toml, но не используется в коде.
  - `once_cell`: Перечислена, но не найдена в коде.
  - `uuid`: В dev-dependencies, но не используется в тестах.
  - `encoding_rs`: Возможно, транзитивная зависимость reqwest, но явно указана.

### 3. Отсутствие тестов
- Проект имеет минимальное тестовое покрытие. Только один тест в `robots.rs`.
- Рекомендуется добавить unit-тесты для основных функций: валидация URL, парсинг HTML, извлечение метаданных, поиск и т.д.
- Интеграционные тесты для инструментов MCP.

### 4. Производительность и оптимизации
- **Кэширование**: В `fetch.rs` кэш с размером 100 и TTL 300 сек. Для высоконагруженного сервера может быть недостаточно. Рассмотреть увеличение размера кэша или использование внешнего кэша (Redis).
- **Таймауты**: HTTP таймаут 30 сек может быть слишком долгим для некоторых случаев. Рассмотреть конфигурируемые таймауты.
- **Память**: Для больших страниц контент загружается полностью в память. Для очень больших страниц (>10MB) может вызвать OOM. Рассмотреть streaming или лимиты.
- **Конкурентность**: В batch fetch используется governor для rate limiting, но нет защиты от слишком большого числа одновременных запросов глобально.

### 5. Безопасность
- **Robots.txt**: Проверка robots.txt корректна, но пользователь может отключить её флагом `--ignore-robots-txt`. Это нормально для автономного использования.
- **URL валидация**: Хорошо реализована, ограничивает только HTTP/HTTPS.
- **CSS селекторы**: Ограничение длины 1000 символов хорошо против DoS.
- **Regex паттерны**: Ограничение 500 символов хорошо против ReDoS.
- **Зависимости**: Рекомендуется проверить на уязвимости с помощью `cargo audit`.

### 6. Кодстайл и поддерживаемость
- Код хорошо структурирован, использует async/await корректно.
- Используются современные Rust паттерны (impl blocks, derive macros).
- Логирование с tracing хорошо настроено.
- Документация в README.md присутствует.

## План исправлений
1. **Высокий приоритет**:
   - Добавить валидацию для `start_index` в fetch tool.
   - Удалить мертвый код (detect_content_type).
   - Удалить неиспользуемые зависимости.

2. **Средний приоритет**:
   - Реализовать HTTP stream mode или убрать аргумент.
   - Добавить базовые unit-тесты для ключевых функций.
   - Проверить и обновить зависимости на актуальные версии.

3. **Низкий приоритет**:
   - Оптимизировать кэширование и таймауты.
   - Добавить интеграционные тесты.
   - Рассмотреть добавление метрик (prometheus) для мониторинга.

## Заключение
Приложение в хорошем состоянии, компилируется без ошибок. Основные проблемы - отсутствие тестов и небольшой мертвый код. С исправлениями станет более надежным и поддерживаемым.